{"ast":null,"code":"export const dataEngineeringTerms = [{\n  id: 1,\n  term: \"ETL\",\n  definition: \"Extract, Transform, Load - process of extracting data from sources, transforming it, and loading into a destination.\",\n  howToUse: \"Used to move data from transactional databases to data warehouses. Implement using tools like Apache Airflow, Talend, or custom Python scripts.\",\n  whenToUse: \"When migrating data between systems, creating data pipelines, or preparing data for analytics.\",\n  category: \"Data Processing\",\n  difficulty: \"Beginner\"\n}, {\n  id: 2,\n  term: \"Data Lake\",\n  definition: \"A centralized repository that allows you to store all your structured and unstructured data at any scale.\",\n  howToUse: \"Implement using cloud services like AWS S3, Azure Data Lake, or Hadoop HDFS. Store raw data in its native format.\",\n  whenToUse: \"When you need to store vast amounts of raw data for future processing or when schema-on-read is required.\",\n  category: \"Storage\",\n  difficulty: \"Intermediate\"\n}\n// Add more terms...\n];","map":{"version":3,"names":["dataEngineeringTerms","id","term","definition","howToUse","whenToUse","category","difficulty"],"sources":["C:/Users/CAPACITI-JHB/OneDrive/Desktop/bright-de-ai-assistant/data-engineering-assistant/src/data/termsData.js"],"sourcesContent":["export const dataEngineeringTerms = [\r\n  {\r\n    id: 1,\r\n    term: \"ETL\",\r\n    definition: \"Extract, Transform, Load - process of extracting data from sources, transforming it, and loading into a destination.\",\r\n    howToUse: \"Used to move data from transactional databases to data warehouses. Implement using tools like Apache Airflow, Talend, or custom Python scripts.\",\r\n    whenToUse: \"When migrating data between systems, creating data pipelines, or preparing data for analytics.\",\r\n    category: \"Data Processing\",\r\n    difficulty: \"Beginner\"\r\n  },\r\n  {\r\n    id: 2,\r\n    term: \"Data Lake\",\r\n    definition: \"A centralized repository that allows you to store all your structured and unstructured data at any scale.\",\r\n    howToUse: \"Implement using cloud services like AWS S3, Azure Data Lake, or Hadoop HDFS. Store raw data in its native format.\",\r\n    whenToUse: \"When you need to store vast amounts of raw data for future processing or when schema-on-read is required.\",\r\n    category: \"Storage\",\r\n    difficulty: \"Intermediate\"\r\n  },\r\n  // Add more terms...\r\n];"],"mappings":"AAAA,OAAO,MAAMA,oBAAoB,GAAG,CAClC;EACEC,EAAE,EAAE,CAAC;EACLC,IAAI,EAAE,KAAK;EACXC,UAAU,EAAE,sHAAsH;EAClIC,QAAQ,EAAE,iJAAiJ;EAC3JC,SAAS,EAAE,gGAAgG;EAC3GC,QAAQ,EAAE,iBAAiB;EAC3BC,UAAU,EAAE;AACd,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,IAAI,EAAE,WAAW;EACjBC,UAAU,EAAE,2GAA2G;EACvHC,QAAQ,EAAE,mHAAmH;EAC7HC,SAAS,EAAE,2GAA2G;EACtHC,QAAQ,EAAE,SAAS;EACnBC,UAAU,EAAE;AACd;AACA;AAAA,CACD","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}
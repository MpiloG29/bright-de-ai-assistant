export const courses = [
  {
    id: 1,
    title: "Data Engineering Fundamentals",
    description: "Learn the basics of data pipelines, ETL, and data warehousing. Perfect for beginners starting their data engineering journey.",
    duration: "8 weeks",
    level: "Beginner",
    progress: 30,
    modules: 6,
    topics: ["SQL Fundamentals", "Python Basics", "Data Modeling", "ETL Concepts", "Data Warehousing", "Introduction to Cloud"]
  },
  {
    id: 2,
    title: "Big Data Technologies",
    description: "Master Hadoop, Spark, and distributed computing frameworks for processing large-scale data.",
    duration: "10 weeks",
    level: "Intermediate",
    progress: 15,
    modules: 8,
    topics: ["Hadoop Ecosystem", "Apache Spark", "Hive & HBase", "Distributed Systems", "Data Lakes", "Performance Tuning"]
  },
  {
    id: 3,
    title: "Cloud Data Engineering",
    description: "Learn to build data pipelines on AWS, Azure, and Google Cloud Platform.",
    duration: "12 weeks",
    level: "Intermediate",
    progress: 5,
    modules: 10,
    topics: ["AWS Redshift", "Azure Data Factory", "Google BigQuery", "Cloud Storage", "Serverless Data Processing", "Data Security"]
  },
  {
    id: 4,
    title: "Real-time Data Processing",
    description: "Build streaming data pipelines with Kafka, Flink, and Spark Streaming.",
    duration: "6 weeks",
    level: "Advanced",
    progress: 0,
    modules: 5,
    topics: ["Apache Kafka", "Flink Streaming", "Spark Streaming", "Event-driven Architecture", "Stream Processing Patterns"]
  },
  {
    id: 5,
    title: "Data Pipeline Orchestration",
    description: "Master workflow orchestration with Apache Airflow, Luigi, and Prefect.",
    duration: "8 weeks",
    level: "Intermediate",
    progress: 0,
    modules: 7,
    topics: ["Apache Airflow", "DAG Design", "Task Dependencies", "Monitoring", "Error Handling", "Best Practices"]
  },
  {
    id: 6,
    title: "Data Quality and Testing",
    description: "Ensure data reliability with comprehensive testing and quality frameworks.",
    duration: "4 weeks",
    level: "Intermediate",
    progress: 0,
    modules: 4,
    topics: ["Data Validation", "Testing Strategies", "Quality Metrics", "Monitoring", "Great Expectations"]
  },
  {
    id: 7,
    title: "DataOps Fundamentals",
    description: "Apply DevOps principles to data engineering for faster, more reliable pipelines.",
    duration: "6 weeks",
    level: "Advanced",
    progress: 0,
    modules: 6,
    topics: ["CI/CD for Data", "Infrastructure as Code", "Monitoring & Alerting", "Collaboration", "Automation"]
  },
  {
    id: 8,
    title: "Interview Preparation",
    description: "Prepare for data engineering interviews with real questions and mock interviews.",
    duration: "4 weeks",
    level: "All Levels",
    progress: 45,
    modules: 5,
    topics: ["Technical Questions", "System Design", "Coding Challenges", "Behavioral Questions", "Mock Interviews"]
  }
];